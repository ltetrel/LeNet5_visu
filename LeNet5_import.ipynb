{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 19.0.2, however version 19.0.3 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip --quiet install lucid\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import lucid.optvis.param as param\n",
    "import lucid.optvis.render as render\n",
    "from lucid.misc.io.showing import _image_url, _display_html\n",
    "from lucid.modelzoo.vision_base import Model\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frozen_graph(filename, output_channels):\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(sess\n",
    "                                                                    , tf.get_default_graph().as_graph_def()\n",
    "                                                                    , output_channels)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "# def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "#     \"\"\"\n",
    "#     Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "#     Creates a new computation graph where variable nodes are replaced by\n",
    "#     constants taking their current value in the session. The new graph will be\n",
    "#     pruned so subgraphs that are not necessary to compute the requested\n",
    "#     outputs are removed.\n",
    "#     @param session The TensorFlow session to be frozen.\n",
    "#     @param keep_var_names A list of variable names that should not be frozen,\n",
    "#                           or None to freeze all the variables in the graph.\n",
    "#     @param output_names Names of the relevant graph outputs.\n",
    "#     @param clear_devices Remove the device directives from the graph for better portability.\n",
    "#     @return The frozen graph definition.\n",
    "#     \"\"\"\n",
    "#     graph = session.graph\n",
    "#     with graph.as_default():\n",
    "#         freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "#         output_names = output_names or []\n",
    "#         output_names += [v.op.name for v in tf.global_variables()]\n",
    "#         input_graph_def = graph.as_graph_def()\n",
    "#         if clear_devices:\n",
    "#             for node in input_graph_def.node:\n",
    "#                 node.device = \"\"\n",
    "       \n",
    "#         frozen_graph = tf.compat.v1.graph_util.convert_variables_to_constants(session, input_graph_def,\n",
    "#                                                       output_names, freeze_var_names)\n",
    "#         return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to output tensorboard\n",
    "def tensorboard_view(session):\n",
    "    log_dir = \"/notebooks/yu_gpu_cpu_profile/LeNetVisu/logs/\"\n",
    "    \n",
    "    writer = tf.summary.FileWriter(log_dir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    !tensorboard --logdir=\"/notebooks/yu_gpu_cpu_profile/LeNetVisu/logs/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from LeNet5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from LeNet5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d/Relu\n",
      "conv2d_1/Relu\n",
      "dense/Relu\n",
      "dense_1/Softmax\n",
      "WARNING:tensorflow:From <ipython-input-2-709752a63db8>:4: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-709752a63db8>:4: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 8 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "img_rows = x_train.shape[1]\n",
    "img_cols = x_train.shape[2]\n",
    "\n",
    "#preprocessing data\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "saver = tf.train.import_meta_graph(\"LeNet5.meta\")\n",
    "saver.restore(sess, \"LeNet5\")\n",
    "\n",
    "ops = sess.graph.get_operations()\n",
    "tensors_names = [m.name for m in ops]\n",
    "# we hope that the first name is always the first tensor..\n",
    "tensor_input = tensors_names[0]\n",
    "# for the outputs, we check for all the operations with activations..\n",
    "tensor_outputs = []\n",
    "for s in tensors_names:\n",
    "    if re.match(\".*?(/Relu|/Softmax)$\", s):\n",
    "        print(s)\n",
    "        tensor_outputs += [s]\n",
    "\n",
    "# https://gist.github.com/BadrYoubiIdrissi/b2631fddeabf0d8563c6d51cd2055c56\n",
    "save_frozen_graph('LeNet5.pb', tensor_outputs)\n",
    "\n",
    "# creating the frozen graph as in\n",
    "# https://colab.research.google.com/drive/1PPzeZi5sBN2YRlBmKsdvZPbfYtZI-pHl#scrollTo=eju-KLeJ-kBK\n",
    "# and\n",
    "# https://colab.research.google.com/drive/1OFesr3ceAaPGmU_gNtDy1djn_9GZgI81#scrollTo=Za1OnQIyDbpJ&forceEdit=true&offline=true&sandboxMode=true\n",
    "\n",
    "# frozen_graph = freeze_session(sess, output_names=tensor_outputs)\n",
    "# tf.train.write_graph(frozen_graph, \".\", \"LeNet5.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1/Softmax0..."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot execute operation using `run()`: No default session is registered. Use `with sess.as_default():` or pass an explicit session to `run(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8f7fcf0ca6ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#                    param_f=param.color.to_valid_rgb(param.spatial.naive((1,28,28,1))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         image = render_vis(model, tensor_outputs[-1] + \":{}\".format(softmax_idx),\n\u001b[0;32m---> 38\u001b[0;31m                    steps=128, param_f=param.color.to_valid_rgb(param.spatial.naive((1,28,28,1))))\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mlogit_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-8f7fcf0ca6ac>\u001b[0m in \u001b[0;36mrender_vis\u001b[0;34m(model, objective_f, param_f, steps)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrender_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_vis_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vis_op\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lucid/optvis/render.py\u001b[0m in \u001b[0;36mmake_vis_T\u001b[0;34m(model, objective_f, param_f, optimizer, transforms, relu_gradient_override)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0minit_global_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0minit_global_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mrelu_gradient_override\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m     \"\"\"\n\u001b[0;32m-> 2450\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5200\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5202\u001b[0;31m       raise ValueError(\"Cannot execute operation using `run()`: No default \"\n\u001b[0m\u001b[1;32m   5203\u001b[0m                        \u001b[0;34m\"session is registered. Use `with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5204\u001b[0m                        \u001b[0;34m\"sess.as_default():` or pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot execute operation using `run()`: No default session is registered. Use `with sess.as_default():` or pass an explicit session to `run(session=sess)`"
     ]
    }
   ],
   "source": [
    "def show_images(images):\n",
    "    html = \"\"\n",
    "    for image in images:\n",
    "        data_url = _image_url(image)\n",
    "        html += '<img width=\\\"100\\\" style=\\\"margin: 10px\\\" src=\\\"' + data_url + '\\\">'\n",
    "        _display_html(html)\n",
    "\n",
    "def render_vis(model, objective_f, param_f, steps=512):\n",
    "    T = render.make_vis_T(model, objective_f, param_f, optimizer=None, transforms=[])\n",
    "    loss, vis_op, t_image = T(\"loss\"), T(\"vis_op\"), T(\"input\")\n",
    "    sess = tf.Session()\n",
    "    sess.as_default()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(steps):\n",
    "        sess.run(vis_op)\n",
    "    return sess.run(t_image)\n",
    "\n",
    "class LeNet5Model(Model):\n",
    "    model_path = './LeNet5.pb'\n",
    "    image_shape = [1, 28, 28, 1]\n",
    "    image_value_range = (0., 1.)\n",
    "    input_name = tensor_input\n",
    "\n",
    "model = LeNet5Model()\n",
    "model.load_graphdef()\n",
    "\n",
    "# for node in model.graph_def.node:\n",
    "#     print(node.)\n",
    "\n",
    "softmax_images = []\n",
    "print(tensor_outputs[-1], end=\"\")\n",
    "for softmax_idx in range(10):\n",
    "    print(\"{}...\".format(softmax_idx), end=\"\")\n",
    "    with tf.Graph().as_default():\n",
    "#         _ = render.render_vis(model, tensor_outputs[-1] + \":{}\".format(softmax_idx),\n",
    "#                    param_f=param.color.to_valid_rgb(param.spatial.naive((1,28,28,1))))\n",
    "        image = render_vis(model, tensor_outputs[-1] + \":{}\".format(softmax_idx),\n",
    "                   steps=128, param_f=param.color.to_valid_rgb(param.spatial.naive((1,28,28,1))))\n",
    "        logit_images.append(image)\n",
    "show_images(logit_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.misc.io import show\n",
    "import lucid.misc.io.showing as showing\n",
    "from lucid.misc.channel_reducer import ChannelReducer\n",
    "import lucid.optvis.param as param\n",
    "import lucid.optvis.objectives as objectives\n",
    "import lucid.optvis.render as render\n",
    "from lucid.misc.io import show, load\n",
    "from lucid.misc.io.reading import read\n",
    "from lucid.misc.io.showing import _image_url\n",
    "import lucid.scratch.web.svelte as lucid_svelte\n",
    "from lucid.misc.gradient_override import gradient_override_map\n",
    "\n",
    "def raw_class_group_attr(img, layer, label, group_vecs, override=None): \n",
    "    \"\"\"How much did spatial positions at a given layer effect a output class?\"\"\"\n",
    "    # Set up a graph for doing attribution...\n",
    "    with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
    "        t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
    "        T = render.import_model(model, t_input, t_input)\n",
    "\n",
    "        # Compute activations\n",
    "        acts = T(layer).eval()\n",
    "\n",
    "        if label is None: return np.zeros(acts.shape[1:-1])\n",
    "\n",
    "        # Compute gradient\n",
    "        score = T(\"softmax2_pre_activation\")[0, labels.index(label)]\n",
    "        t_grad = tf.gradients([score], [T(layer)])[0]   \n",
    "        grad = t_grad.eval({T(layer) : acts})\n",
    "\n",
    "        # Linear approximation of effect of spatial position\n",
    "        return [np.sum(group_vec * grad) for group_vec in group_vecs]\n",
    "    \n",
    "def neuron_groups(img, layer, n_groups=6, attr_classes=[]):\n",
    "\n",
    "    # Compute activations\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session():\n",
    "        t_input = tf.placeholder_with_default(img, [1, 28, 28])\n",
    "        T = render.import_model(model, t_input, t_input)\n",
    "        acts = T(layer).eval()\n",
    "\n",
    "    # We'll use ChannelReducer (a wrapper around scikit learn's factorization tools)\n",
    "    # to apply Non-Negative Matrix factorization (NMF).\n",
    "\n",
    "    nmf = ChannelReducer(n_groups, \"NMF\")\n",
    "    spatial_factors = nmf.fit_transform(acts)[0].transpose(2, 0, 1).astype(\"float32\")\n",
    "    channel_factors = nmf._reducer.components_.astype(\"float32\")\n",
    "\n",
    "    # Let's organize the channels based on their horizontal position in the image\n",
    "\n",
    "    x_peak = np.argmax(spatial_factors.max(1), 1)\n",
    "    ns_sorted = np.argsort(x_peak)\n",
    "    spatial_factors = spatial_factors[ns_sorted]\n",
    "    channel_factors = channel_factors[ns_sorted]\n",
    "\n",
    "    # And create a feature visualziation of each group\n",
    "\n",
    "    param_f = lambda: param.image(80, batch=n_groups)\n",
    "    obj = sum(objectives.direction(layer, channel_factors[i], batch=i)\n",
    "            for i in range(n_groups))\n",
    "    group_icons = render.render_vis(model, obj, param_f, verbose=False)[-1]\n",
    "\n",
    "    # We'd also like to know about attribution\n",
    "\n",
    "    # First, let's turn each group into a vector over activations\n",
    "    group_vecs = [spatial_factors[i, ..., None]*channel_factors[i]\n",
    "                for i in range(n_groups)]\n",
    "\n",
    "    attrs = np.asarray([raw_class_group_attr(img, layer, attr_class, group_vecs)\n",
    "                     for attr_class in attr_classes])\n",
    "\n",
    "    print(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5Model()\n",
    "model.load_graphdef()\n",
    "\n",
    "neuron_groups(x_test[3,:,:,:], \"conv2d/Relu\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /usr/local/cuda/include/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline  \n",
    "plt.imshow(x_test[3,0,:,:], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(param.color.to_valid_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.train.load_variable(\"/notebooks/yu_gpu_cpu_profile/LeNetVisu/\", \"conv2d/kernel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.train.load_variable(\"/notebooks/yu_gpu_cpu_profile/LeNetVisu/\", \"conv2d/kernel_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we can do inference\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# trying to predict with the model\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"LeNet5.meta\", clear_devices=True)\n",
    "    saver.restore(sess, \"LeNet5\")    \n",
    "    x_tensor = sess.graph.get_tensor_by_name(\"conv2d_input:0\")\n",
    "    y_tensor = sess.graph.get_tensor_by_name(\"dense_1/Softmax:0\")\n",
    "    print(sess.run(y_tensor, feed_dict={x_tensor: x_test[0:1,:,:,:]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all tensors from a tensorflow graph\n",
    "ops = sess.graph.get_operations()\n",
    "# just the tensor names\n",
    "tensors_names = [m.name for m in ops]\n",
    "\n",
    "# all the tensor informations\n",
    "tensors = [m.values() for m in ops]\n",
    "\n",
    "# More clear way\n",
    "for operation in ops:\n",
    "    print(\"Operation:\",operation.name)\n",
    "    #for k in operation.inputs:\n",
    "    #    print(operation.name,\"Input \",k.name,k.get_shape())\n",
    "    #for k in operation.outputs:\n",
    "    #    print(operation.name,\"Output \",k.name)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check all weights from tensorflow session\n",
    "vars_global = tf.global_variables()\n",
    "\n",
    "# get their name and value and put them into dictionary\n",
    "sess.as_default()\n",
    "model_vars = {}\n",
    "for var in vars_global:\n",
    "    try:\n",
    "        model_vars[var.name] = var.eval()\n",
    "    except:\n",
    "        print(\"For var={}, an exception occurred\".format(var.name))\n",
    "\n",
    "model_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check weights from a tensorflow checkpoint\n",
    "print(tf.train.load_variable(\"/notebooks/yu_gpu_cpu_profile/LeNetVisu/\", \"conv2d/kernel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click-7.0.dist-info\r\n",
      "IPython\r\n",
      "Jinja2-2.10.dist-info\r\n",
      "Keras_Applications-1.0.7.dist-info\r\n",
      "Keras_Preprocessing-1.0.9.dist-info\r\n",
      "Markdown-3.0.1.dist-info\r\n",
      "MarkupSafe-1.1.0.dist-info\r\n",
      "OpenGL\r\n",
      "PIL\r\n",
      "Pillow-5.4.1.dist-info\r\n",
      "PyOpenGL-3.1.0.dist-info\r\n",
      "Pygments-2.3.1.dist-info\r\n",
      "Send2Trash-1.5.0.dist-info\r\n",
      "Werkzeug-0.14.1.dist-info\r\n",
      "__pycache__\r\n",
      "absl\r\n",
      "absl_py-0.7.0.dist-info\r\n",
      "astor\r\n",
      "astor-0.7.1.dist-info\r\n",
      "backcall\r\n",
      "backcall-0.1.0.dist-info\r\n",
      "bleach\r\n",
      "bleach-3.1.0.dist-info\r\n",
      "bz2file-0.98.dist-info\r\n",
      "bz2file.py\r\n",
      "cachetools\r\n",
      "cachetools-3.1.0.dist-info\r\n",
      "click\r\n",
      "cycler-0.10.0.dist-info\r\n",
      "cycler.py\r\n",
      "dateutil\r\n",
      "decorator-4.3.2.dist-info\r\n",
      "decorator.py\r\n",
      "defusedxml\r\n",
      "defusedxml-0.5.0.dist-info\r\n",
      "easy_install.py\r\n",
      "entrypoints-0.3.dist-info\r\n",
      "entrypoints.py\r\n",
      "enum\r\n",
      "enum34-1.1.6.dist-info\r\n",
      "filelock-3.0.10.dist-info\r\n",
      "filelock.py\r\n",
      "future\r\n",
      "future-0.17.1.dist-info\r\n",
      "gast\r\n",
      "gast-0.2.2.dist-info\r\n",
      "google\r\n",
      "grpc\r\n",
      "grpcio-1.18.0.dist-info\r\n",
      "h5py\r\n",
      "h5py-2.9.0.dist-info\r\n",
      "ipykernel\r\n",
      "ipykernel-5.1.0.dist-info\r\n",
      "ipykernel_launcher.py\r\n",
      "ipython-7.2.0.dist-info\r\n",
      "ipython_genutils\r\n",
      "ipython_genutils-0.2.0.dist-info\r\n",
      "ipywidgets\r\n",
      "ipywidgets-7.4.2.dist-info\r\n",
      "jedi\r\n",
      "jedi-0.13.2.dist-info\r\n",
      "jinja2\r\n",
      "jsonschema\r\n",
      "jsonschema-2.6.0.dist-info\r\n",
      "jupyter-1.0.0.dist-info\r\n",
      "jupyter.py\r\n",
      "jupyter_client\r\n",
      "jupyter_client-5.2.4.dist-info\r\n",
      "jupyter_console\r\n",
      "jupyter_console-6.0.0.dist-info\r\n",
      "jupyter_core\r\n",
      "jupyter_core-4.4.0.dist-info\r\n",
      "jupyter_http_over_ws\r\n",
      "jupyter_http_over_ws-0.0.2.dist-info\r\n",
      "keras_applications\r\n",
      "keras_preprocessing\r\n",
      "kiwisolver-1.0.1.dist-info\r\n",
      "kiwisolver.cpython-35m-x86_64-linux-gnu.so\r\n",
      "libfuturize\r\n",
      "libpasteurize\r\n",
      "llvmlite\r\n",
      "llvmlite-0.27.0.dist-info\r\n",
      "lucid\r\n",
      "lucid-0.3.8.dist-info\r\n",
      "markdown\r\n",
      "markupsafe\r\n",
      "matplotlib\r\n",
      "matplotlib-3.0.2-py3.5-nspkg.pth\r\n",
      "matplotlib-3.0.2.dist-info\r\n",
      "mistune-0.8.4.dist-info\r\n",
      "mistune.py\r\n",
      "mock\r\n",
      "mock-2.0.0.dist-info\r\n",
      "more_itertools\r\n",
      "more_itertools-6.0.0.dist-info\r\n",
      "mpl_toolkits\r\n",
      "nbconvert\r\n",
      "nbconvert-5.4.1.dist-info\r\n",
      "nbformat\r\n",
      "nbformat-4.4.0.dist-info\r\n",
      "nibabel\r\n",
      "nibabel-2.3.3.dist-info\r\n",
      "nilearn\r\n",
      "nilearn-0.5.0.dist-info\r\n",
      "nisext\r\n",
      "notebook\r\n",
      "notebook-5.7.4.dist-info\r\n",
      "numba\r\n",
      "numba-0.42.0.dist-info\r\n",
      "numexpr\r\n",
      "numexpr-2.6.9.dist-info\r\n",
      "numpy\r\n",
      "numpy-1.16.1.dist-info\r\n",
      "pandocfilters-1.4.2.dist-info\r\n",
      "pandocfilters.py\r\n",
      "parso\r\n",
      "parso-0.3.4.dist-info\r\n",
      "past\r\n",
      "pbr\r\n",
      "pbr-5.1.2.dist-info\r\n",
      "pexpect\r\n",
      "pexpect-4.6.0.dist-info\r\n",
      "pickleshare-0.7.5.dist-info\r\n",
      "pickleshare.py\r\n",
      "pip\r\n",
      "pip-19.0.2.dist-info\r\n",
      "pkg_resources\r\n",
      "prometheus_client\r\n",
      "prometheus_client-0.5.0.dist-info\r\n",
      "prompt_toolkit\r\n",
      "prompt_toolkit-2.0.8.dist-info\r\n",
      "protobuf-3.6.1-py3.5-nspkg.pth\r\n",
      "protobuf-3.6.1.dist-info\r\n",
      "ptyprocess\r\n",
      "ptyprocess-0.6.0.dist-info\r\n",
      "pygments\r\n",
      "pylab.py\r\n",
      "pyparsing-2.3.1.dist-info\r\n",
      "pyparsing.py\r\n",
      "python_dateutil-2.8.0.dist-info\r\n",
      "pyzmq-17.1.2.dist-info\r\n",
      "qtconsole\r\n",
      "qtconsole-4.4.3.dist-info\r\n",
      "scikit_learn-0.20.2.dist-info\r\n",
      "scipy\r\n",
      "scipy-1.2.1.dist-info\r\n",
      "send2trash\r\n",
      "setuptools\r\n",
      "setuptools-40.8.0.dist-info\r\n",
      "six-1.12.0.dist-info\r\n",
      "six.py\r\n",
      "sklearn\r\n",
      "tables\r\n",
      "tables-3.4.4.dist-info\r\n",
      "tensorboard\r\n",
      "tensorboard-1.12.2.dist-info\r\n",
      "tensorflow\r\n",
      "tensorflow_estimator\r\n",
      "tensorflow_estimator-1.13.0rc0.dist-info\r\n",
      "tensorflow_gpu-1.13.0rc2.dist-info\r\n",
      "termcolor-1.1.0.dist-info\r\n",
      "termcolor.py\r\n",
      "terminado\r\n",
      "terminado-0.8.1.dist-info\r\n",
      "testpath\r\n",
      "testpath-0.4.2.dist-info\r\n",
      "tornado\r\n",
      "tornado-5.1.1.dist-info\r\n",
      "traitlets\r\n",
      "traitlets-4.3.2.dist-info\r\n",
      "umap\r\n",
      "umap_learn-0.3.7.dist-info\r\n",
      "wcwidth\r\n",
      "wcwidth-0.1.7.dist-info\r\n",
      "webencodings\r\n",
      "webencodings-0.5.1.dist-info\r\n",
      "werkzeug\r\n",
      "widgetsnbextension\r\n",
      "widgetsnbextension-3.4.2.dist-info\r\n",
      "zmq\r\n"
     ]
    }
   ],
   "source": [
    "!ls /usr/local/lib/python3.5/dist-packages/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
